{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_auqff4d"
   },
   "source": [
    "# <span class=\"motutor-highlight motutor-id_auqff4d-id_vlngv2v\"><i></i>Non-IID问题以及数据集</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_ch7s5aj"
   },
   "source": [
    "<img src=\"https://imgbed.momodel.cn/charts.png\" width=750 />\n",
    "\n",
    "如上图，我们可得出IID的数据对模型训练的收敛速度是Non-IID数据集收敛速度的平均2倍左右。表明数据集的分布对模型训练具有重大影响。而公开的数据集都是基于独立同分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_1mvsw83"
   },
   "source": [
    "### 对Non-IID分类\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/ne1.png\" width=750 />\n",
    "\n",
    "定义输入的数据特征为$x$,对用的label为$y$,$P$代表概率：\n",
    "\n",
    "数据集的非独立同分布特性主要表现在三个方面上：\n",
    "\n",
    "   - **不同客户端数据分布不同**： $(x,y) \\sim \\mathcal{P}_i(x,y)\\not= \\mathcal{P}_j(x,y)$\n",
    "     - 特征分布倾斜：$\\mathcal{P}(y|x)$相同，$\\mathcal{P}(x)$不同；不同人的笔迹不同\n",
    "     - 标签分布倾斜：$\\mathcal{P}(y|x)$相同，$\\mathcal{P}(y)$不同；企鹅在只在南极、北极熊只在北极\n",
    "     - 标签相同特征不同：$\\mathcal{P}(y)$相同，$\\mathcal{P}(y|x)$不同；概念飘移；相同的数字7，南北方不同的手势\n",
    "     - 特征相同标签不同：$\\mathcal{P}(x)$相同，$\\mathcal{P}(y|x)$不同；点头表示Yes / No?\n",
    "     - 数量不平衡\n",
    "   - **数据偏移**：训练集和测试集具有不同分布\n",
    "   - **非独立**：可用节点大多在附近时区（地理位置非独立）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_42pkpob"
   },
   "source": [
    "#### 协变量偏移\n",
    "<img src=\"https://imgbed.momodel.cn/cse1.png\" width=750 />\n",
    "\n",
    "协变量偏移即指数据集的标签分布相同，但是数据的特征分布有差异。\n",
    "\n",
    "在联邦学习场景下，这是很常见的。同一个标签所对应训练集数据具有部分不同的特征，例如，手写识别中每一个人书写同样的数字“3”，如下图展示了每个人书写字体的粗细，大小不一定完全一致。例如真实生活中人脸识别中，全世界的人类的脸相似，但是如下图中每人眼窝的深浅，鼻梁的高矮等仍然是不相同的。\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/333.png\" width=750 />\n",
    "<img src=\"https://imgbed.momodel.cn/face.png\" width=750 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_elxv2ja"
   },
   "source": [
    "在这种情况下，输入和输出之间的基础关系没有变化（回归仍然相同），但是该关系的一部分是数据稀疏，被遗漏或被错误表示。\n",
    "\n",
    "当执行交叉验证时，协变量偏移会引起很多问题。 没有协变量偏移，交叉验证几乎是稳定的。但是在协变量偏移下，交叉验证有很大的偏差！\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/cs.png\" width=750 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_fbyw8vh"
   },
   "source": [
    "#### 先验概率偏移\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/pse2.png\" width=750 />\n",
    "\n",
    "尽管协变量偏移着重于特征（x）分布的变化，但先验概率移位着重于类变量y分布的变化。\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/ps.png\" width=750 />\n",
    "\n",
    "例如，目前全世界上大熊猫特征相同，由于地域限制，他们主要数量分布在中国的四川。\n",
    "从数学角度，先验概率偏移可定义为联邦学习中 $P_{i}(x│y)$保持相同， $P_{i}(y)$在各个节点上是不同的。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_nubydjc"
   },
   "source": [
    "### 概念偏移\n",
    "\n",
    "概念偏移与协变量和先验概率偏移的不同之处在于，它与数据分布或类分布无关，而与两个变量之间的关系有关。\n",
    "\n",
    "在时间序列分析中，通常在执行任何分析之前先检查时间序列是否固定，因为固定时间序列比非固定时间序列要容易得多。 如下图\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/con1.png\" width=750 />\n",
    "\n",
    "举一个更具体的例子，假设我们检查了2008年金融危机之前公司的利润，并根据行业，员工人数，产品信息等因素制定了一种预测利润的算法。 如果我们的算法是针对2000-2007年的数据进行训练的，但是在金融危机之后，该算法的效果可能会很差。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_ns4zq79"
   },
   "source": [
    "### 节点上数据数量不同\n",
    "\n",
    "显然每轮参加训练的节点中数量的不同也会影响到模型的精度，收敛速度等。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_ntadusr"
   },
   "source": [
    "## 当前数据集方案"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_yr2n4f5"
   },
   "source": [
    "### LEAF数据集\n",
    "\n",
    "Caldas等人提出了LEAF: A Benchmark for Federated Settings，是一个面向联邦学习的基准数据集和模块化测试框架。其中框架主要分为**一套公开的联邦数据集**（包括FEMNIST，Sentiment140，莎士比亚数据集等）、**一个评价框架**、以及**一系列参考实现**：\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/struct.png\" width=750 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_z1crosl"
   },
   "source": [
    "LAEF的数据集允许研究人员在任务和样本数量众多的情况下测试性能。缺点是未能很好总结非独立同分布的分布情况，只采用了均值与方差，未能深入研究分布特性。另外该框架未能针对公开的数据集进行转换改进。\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/leaf1.png\" width=750 />\n",
    "<img src=\"https://imgbed.momodel.cn/leaf2.png\" width=750 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_8wgf23g"
   },
   "source": [
    "### NICO数据集 \n",
    "\n",
    "该文章构建了一个名为NICO的非独立同分布图像数据集，它使用概念(concept)+上下文(context)二维分类图像来进行创建非独立同分布。\n",
    "\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/nico1.png\" width=750 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_uhyz5rg"
   },
   "source": [
    "到目前为止，NICO共包含19个类、188个上下文和近27500个图像。规模还在不断扩大，目前的规模已经能够从零开始支持深卷积网络的训练。\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/nico2.png\" width=750 />\n",
    "\n",
    "文章提出了如何量化衡量训练集和测试集的分布变化程度，并且根据概念和上下文不同构建了NICO数据集。然而缺点主要是没有针对联邦学习场景中的数据集分布情况研究，NI公式的普适性不够广泛。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_xbnfrtn"
   },
   "source": [
    "## 联邦学习 Non-IID 数据生成\n",
    "\n",
    "我们提出了一套非独立同分布数据集的生成方案，该方案可以对公开数据集(MNIST, CIFAR10等)进行改造定制化生成。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_ua4q94k"
   },
   "source": [
    "## Non-IID指标 - NEI值\n",
    "\n",
    "提出用Non-IID指标来量化数据集之间分布的情况与离散程度。\n",
    "\n",
    "模型的训练任务通常分为特征提取$g_{φ}(∙)$和任务分类$f_{θ}(∙)$两个部分。换言之，模型在数据集上迭代更新其参数来拟合数据集的相应特征，并用特征拟合好的模型参数来预测分类结果。训练好的模型参数某种程度对应着该数据集的分布特征。因此，也可用训练好的模型参数经过归一化处理来代表该数据集的特征。\n",
    "\n",
    "我们提出用AutoEncoder模型中的经典Encoder网络替换特征提取器$g_{φ}(∙)$，Autoencoder自动编码是由Rumelhart在1986年提出，可用于处理高维数据，具有降维效果，并提取主要特征，另外算法稀疏的，可解释性好，现实场景大多满足这种约束，算法较为稳健，符合大多数场景。应用Encoder网络并按如下方式定义非独立同分布指标(Non-IID Encoder Index)：\n",
    "\n",
    "$\\operatorname{NEI}(C)=\\left\\|\\frac{\\overline{\\left(\\operatorname{En}\\left(X_{i}^{C_{i}}\\right)\\right.})-\\overline{\\left(\\operatorname{En}\\left(X_{j}^{C_{j}}\\right)\\right)}}{\\sigma\\left(\\operatorname{En}\\left(X^{C}\\right)\\right)}\\right\\|_{2}$\n",
    "\n",
    "其中$X^{C} = X_{i}^{(C_i)}∪X_{j}^{(C_j)}$，$((∙))$代表一阶矩, 即是期望，$σ(∙)$是标准差, 和 $||∙||$代表2范数, 计算向量之间绝对值差距。\n",
    "\n",
    "该NEI公式即使用相同的Encoder网络，训练不同分布的数据，求得期望并归一化和2范式处理，即代表该数据集的分布特征差异，代表数据集$X_{i}^{(C_i)}$ 和$X_{j}^{(C_j)}$之间的差异程度。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_zp26kbr"
   },
   "source": [
    "\n",
    "提供针对公开数据集(MNIST，CIFAR10)改造方案，可制定化地生成需要的非独立同分布数据集。\n",
    "\n",
    "#### 协变量偏移\n",
    "改变现有数据集（MNIST和CIFAR10数据集）的特征，做法主要有：\n",
    "1. 加入不同程度的高斯噪声，或者椒盐噪声公式，模拟$P_{i}(x)$ 不同分布的情况。\n",
    "2. 可以进行裁剪和改变图像大小，变色，旋转，部分遮挡等操作来模拟$P_{i}(x)$ 不同分布的情况。\n",
    "\n",
    "### 先验概率偏移\n",
    "针对现有数据集（MNIST和CIFAR10数据集）极端情况下，联邦网络中设置n个节点，每个节点都只有一种MNIST标签类别的数据。或者每个节点都只拥有一种CIFAR10标签类别的数据，来模拟边缘概率$P_{i}(y)$不同。\n",
    "\n",
    "### 概念偏移\n",
    "主要是针对CIFAR10，将数据集的标签按照两个维度分解：主体标签和背景特征，这在图像分类识别上也是一种全新的数据集分解方案。例如在CIFAR10的数据集中，先将数据按照猫，狗，马等标签分为10类，然后再在每一类中，如猫的分类中，本文再按照背景是否为在地上，沙发上分类。同样的方式在其他类别一样应用。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_27u5xhv"
   },
   "source": [
    "在下图中展示了该方案的框架内容, 框架平台从下至上包括基础服务模块，分布衡量模块，可制定方法模块，配置文件模块和示例。\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/framwork.png\" width=750 />\n",
    "\n",
    "* 基础服务：基础服务主要是用途提供原始数据，即未处理过的数据，主要用于获取到公开的原始的经典数据，另外还可以用于加入收集的真实数据。\n",
    "\n",
    "* 分布衡量：此模块提供非独立同分布指标公式来量化数据集之间分布的差异。\n",
    "\n",
    "* 可定制方法：该模块对非独立同分布情况进行分类，提供对应的生成方法。\n",
    "\n",
    "* 配置文件：配置文件模块用于配置不同数据集的不同参数，以满足多样化的需求。本文可以通过设置相关参数来精确控制非独立同分布数据集的生成。\n",
    "\n",
    "* 示例：用这些模块生成的示例数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_pwv7uu1"
   },
   "source": [
    "### 部分实验结果\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/77.png\" width=750 />\n",
    "<img src=\"https://imgbed.momodel.cn/dog.png\" width=750 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_ld2pek0"
   },
   "source": [
    "<img src=\"https://imgbed.momodel.cn/result.png\" width=750 />"
   ]
  }
 ],
 "metadata": {
  "graffiti": {
   "firstAuthorId": "dev",
   "id": "id_krylvrf",
   "language": "EN"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
