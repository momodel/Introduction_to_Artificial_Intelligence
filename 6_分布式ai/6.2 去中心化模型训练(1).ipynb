{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_1abtple"
   },
   "source": [
    "# 联邦学习基础\n",
    "\n",
    "## 概念\n",
    "\n",
    "1. <span class=\"motutor-highlight motutor-id_1abtple-id_r8y27ba\"><i></i>什么是联邦学习</span>？\n",
    "\n",
    "   联邦学习（Federated Learning, FL）是一种机器学习方法，客户端（例如，移动设备或多个组织）在中央服务器（例如，服务提供商）的协调下**共同训练模型**，同时保持训练数据的**去中心化及分散性**。\n",
    "\n",
    "   <img src=\"https://imgbed.momodel.cn/FL_intro.png\" width=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_r3ortz1"
   },
   "source": [
    "2. <span class=\"motutor-highlight motutor-id_r3ortz1-id_pzmf1ro\"><i></i>为什么叫“联邦学习”</span>？有什么特点？\n",
    "\n",
    "   因为学习任务是通过由中央服务器协调的参与客户端的松散联邦来解决的，其挑战是**不均衡和Non-IID**（非独立同分布）的数据，分布在大量**不可靠的设备**上，并且依赖于**有限的通信带宽**。\n",
    "\n",
    "3. 为什么要引入“联邦学习”这个概念？\n",
    "\n",
    "   1. **保护隐私**\n",
    "   2. **构建群智**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_p48suta"
   },
   "source": [
    "4. 联邦学习的场景与分类？\n",
    "\n",
    "   根据不同场景，<span class=\"motutor-highlight motutor-id_p48suta-id_69g4zxj\"><i></i>联邦学习可以分为两大类</span>：“**跨设备**”和“**跨孤岛**”。\n",
    "\n",
    "   跨设备：Gboard移动键盘\n",
    "\n",
    "   跨孤岛：医疗数据联邦学习\n",
    "   \n",
    "|          | **跨孤岛**         | **跨设备**           |\n",
    "| :--------: | :------------------: | :--------------------: |\n",
    "| 例子     | 医疗机构           | 手机端应用           |\n",
    "| 节点数量 | 1~100              | 1~10^10              |\n",
    "| 节点状态 | 节点几乎稳定运行   | 大部分节点不在线     |\n",
    "| 主要瓶颈 | 计算瓶颈和通信瓶颈 | WiFi速度，设备不在线 |\n",
    "| Yang分类 | 横向/纵向          | 横向                 |\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_fboxukg"
   },
   "source": [
    " 5. 杨强老师分类：<span class=\"motutor-highlight motutor-id_fboxukg-id_w23b19s\"><i></i>横向联邦学习、纵向联邦学习、联邦迁移学习</span>\n",
    "   \n",
    "   <img src=\"https://imgbed.momodel.cn/vh.png\" width=500 />\n",
    "   \n",
    "   * 横向联邦学习: 在用户特征重叠较多，而用户重叠较少的情况下，把数据集按照横向（即用户维度）切分。\n",
    "   * 纵向联邦学习: 在用户重叠较多，而用户特征重叠较少的情况下，把数据集按照纵向（即特征维度）切分。\n",
    "   * 联邦迁移学习: 在两个数据集的用户与用户特征重叠都较少的情况下，不对数据进行切分，而利用迁移学习国来克服数据或标签不足的情况。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_buvihf1"
   },
   "source": [
    "6. 联邦学习有什么经典的优化算法？\n",
    "\n",
    "   <span class=\"motutor-highlight motutor-id_buvihf1-id_fwt91uy\"><i></i>联邦平均算法（FedAvg）</span>\n",
    "\n",
    "   <img src=\"https://imgbed.momodel.cn/fl1.png\" width=500 />\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_1pxzsbo"
   },
   "source": [
    "7. FedAvg算法的流程？\n",
    "\n",
    "   1. **客户端选择: **服务器从一组符合资格要求的客户端中采样。例如仅在设备连接上wi-fi，且处于空闲状态时，才加入服务器。\n",
    "   \n",
    "   2. **传播：** 选定的客户端从服务器下载当前模型权重和训练程序。\n",
    "   \n",
    "   3. **客户端计算：** 设备执行训练程序，在本地计算对模型的更新，例如在本地数据上运行SGD。\n",
    "   \n",
    "   4. **聚合：** 服务器收集设备更新并汇总。为了提高效率，一旦有足够数量的设备提供结果，就停止收集。\n",
    "   \n",
    "   此阶段也是许多其他技术的集成点，包括：基于隐私的安全聚合，为了通信效率对聚合进行有损压缩，以及差分隐私的噪声添加和更新限幅。\n",
    "   \n",
    "   5. **模型分发：** 服务器根据当前轮次的聚合更新，再更新共享模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_fmo4ppt"
   },
   "source": [
    "8. 移动设备上联邦学习的典型数量级\n",
    "\n",
    "| 总样本大小                 | 10^6~10^10个设备 |\n",
    "| :--------------------------: | :----------------: |\n",
    "| 一轮训练的设备选择数       | 50--5000         |\n",
    "| 参与一个模型训练的总设备数 | 10^5~10^7        |\n",
    "| 模型收敛的总轮数           | 5000--10000      |\n",
    "| 训练时间                   | 1~10天           |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_9td8ral"
   },
   "source": [
    "9. <span class=\"motutor-highlight motutor-id_9td8ral-id_ppnye10\"><i></i>联邦学习和一般分布式机器学习的主要区别</span>？\n",
    "\n",
    "|          | **分布式训练**                                       | **联邦学习**                                                 |\n",
    "| :--------: | :---------------------------------------------------: | :------------------------------------------------------------: |\n",
    "| 数据分布 | 集中存储不固定，可以任意打乱、平衡地分配给所有客户端 | 分散存储且固定，数据无法互通、可能存在数据的Non-IID（非独立同分布） |\n",
    "| 节点数量 | 1~1000                                               | 1~10^10                                                      |\n",
    "| 节点状态 | 所有节点稳定运行                                     | 节点可能不在线                                               |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_3kpol19"
   },
   "source": [
    "10. <span class=\"motutor-highlight motutor-id_3kpol19-id_zsmnfzx\"><i></i>联邦学习和完全去中心化学习的主要区别</span>？\n",
    "\n",
    "|          | 联邦学习                                                     | 完全去中心化（点对点）学习 |\n",
    "| :--------: | :------------------------------------------------------------: | :--------------------------: |\n",
    "| 编排方式 | 中央编排流程服务器或服务负责组织训练，但从未看到原始数据。   | 没有集中的编排流程。       |\n",
    "| 宽域通信 | 中心辐射型拓扑，中心代表服务提供商（通常不包含数据）。 | 对等拓扑，带有动态连接图。 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_unsjcm1"
   },
   "source": [
    "11. 数据集中式分布式学习与跨孤岛/跨设备联邦学习的综合对比？\n",
    "\n",
    "|              | 数据集中式的分布式学习                                       | 跨孤岛的联邦学习                                             | 跨设备的联邦学习                                             |\n",
    "| :------------: | :------------------------------------------------------------: | :------------------------------------------------------------: | :------------------------------------------------------------: |\n",
    "| 设置         | 在大型但“扁平”的数据集上训练模型。客户端是单个群集或数据中心中的计算节点。 | 在数据孤岛上训练模型。客户是不同的组织（例如，医疗或金融）或地理分布的数据中心。 | 客户端是大量的移动或物联网设备                               |\n",
    "| 数据分布     | 数据被集中存储，可以在客户端之间进行混洗和平衡。任何客户端都可以读取数据集的任何部分。 | 数据在本地生成，并保持分散化。每个客户端都存储自己的数据，无法读取其他客户端的数据。数据不是独立或相同分布的。 | 与跨孤岛的数据分布一样                                       |\n",
    "| 组织方式     | 中央式组织                                                   | 中央服务器/服务负责组织，但从未看到原始数据。        | 与跨数据孤岛编排方式一样                                     |\n",
    "| 广域通讯     | 无（在一个数据中心/群集中完全连接客户端）。                  | 中心辐射型拓扑，中心代表服务提供商，分支连接到客户端。 | 与跨孤岛的广域通讯方式一样                                   |\n",
    "| 数据可用性   | 所有客户端都是可用的                                         | 所有客户端都是可用的                                         | 只有一小部分客户可用，通常会有日间或其他变化。   |\n",
    "| 数据分布范围 | 通常1-1000个客户端                                           | 通常2~1000个客户端                                           | 大规模并行，最多10^10个客户端。                              |\n",
    "| 主要瓶颈     | 在假设网络非常快的情况下，计算通常是数据中心的瓶颈。     | 可能是计算和通信量                                           | 通信通常是主要的瓶颈，通常跨设备联邦学习使用wifi或更慢的连接。 |\n",
    "| 可及性     | 每个客户端都有一个标识，允许系统通过此表示访问设备。 | 与数据集中式的分布式学习一样                                 | 无法直接为客户建立索引（即不对用户进行标记）。               |\n",
    "| 客户状态     | 有状态的-每个客户都可以参与到计算的每一轮中，不断地传递状态。 | 有状态的-每个客户都可以参与到计算的每一轮中，不断地传递状态。 | 高度不可靠-预计有5％或更多的客户端参与一轮计算会失败或退出（例如，由于违反了电池，网络或闲置的要求而导致设备无法使用）。 |\n",
    "| 客户可靠性   | 相对较少的失败次数                                           | 相对较少的失败次数。                                         | 无状态的-失败次数多，且每个客户在一个任务中可能只参与一次，因此通常假定在每轮计算中都有从未见过的客户的新样本。 |\n",
    "| 数据分区轴   | 数据可以在客户端之间任意分区/重新分区。                      | 固定分区，能够根据样本分区（横向）或者特征分区（纵向）。     | 根据样本固定分区（横向）。                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_z67yil0"
   },
   "source": [
    "<img src=\"https://imgbed.momodel.cn/scaleFL.png\" width=750 />\n",
    ">Bonawitz, Keith, et al. \"Towards federated learning at scale: System design.\" arXiv preprint arXiv:1902.01046 (2019).\n",
    "\n",
    ">Advances and Open Problems in Federated Learning"
   ]
  }
 ],
 "metadata": {
  "graffiti": {
   "firstAuthorId": "dev",
   "id": "id_7h4sqxd",
   "language": "EN"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
