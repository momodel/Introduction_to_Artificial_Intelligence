{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_dpx985g",
    "inputHidden": false
   },
   "source": [
    "# 元学习与联邦学习\n",
    "\n",
    "## <span class=\"motutor-highlight motutor-id_dpx985g-id_vnlj9ix\"><i></i>元学习</span>\n",
    "\n",
    "元学习， meta learning 也被称为 learning to learn，是一种学习如何学习的学习算法。元学习的学习设置和传统的深度学习有些许不同。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_ssum4w1"
   },
   "source": [
    "### 元学习设置\n",
    "\n",
    "数据集通常会分为 Train-set 和 Test-set ，前者用于模型训练阶段和调参阶段以及验证阶段，后者通常用于模型训练以及调参完毕之后的测试阶段。更详细的来说 Train-set 甚至会分为 Train-set 和 Valid-set 。在 set 中的每一张图片 x 和其对应的标签 y 我们称为一个 sample 。\n",
    "\n",
    "但是在元学习中，我们需要用更高的一个维度来看待这个数据集的设定。\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/t1.png\" width=750 />\n",
    "\n",
    "\n",
    "如上图的左上角所示，我们在元学习的环境下，一个 sample 不再是一个图片和标签，而是一个数据集 set 。\n",
    "\n",
    "一个 train set 和一个 test set 组成一个元学习环境下的 sample ，为了避免混淆，我们将这个 sample 称为 episode 。而前面提到的这个 set ，我们也为了避免混淆取名为 support set和query set。一个support set和query set组成一个episode，多个episode组成了元学习的一个batch，也叫做meta batch。\n",
    "\n",
    "正如图中所展示的，多个episode就组成meta learning中的train-set和test-set，也称为meta training set和meta testing set。\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_zdnf760"
   },
   "source": [
    "### 元学习流程\n",
    "\n",
    "元学习的训练目的主要是为了训练一个元学习器（meta learner），而训练meta learner的时候同时也要训练一个learner。训练过程就是learner首先会通过meta learner获得大量不同的任务，最终learner学习到众多任务中的知识。\n",
    "\n",
    "学习过程通常有两个阶段，第一个阶段式learner具体的去快速学习每一种不同的任务。第二阶段就是meta learner从learner中将所学到的知识缓慢的提取消化。\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/t2.png\" width=750 />\n",
    "\n",
    "如上图所示，其中meta-learner(A)表示的就是元学习器，他同时也是learner的每轮训练的初始参数。当Meta-Learner在某个具体的任务上开始学习时，就成了为了图上所展示的Learner，这个时候指的就是对具体的某个task进行adaptation之后的参数。Loss指代的是某个task的损失函数，通过该损失函数来使得learner进行学习。\n",
    "\n",
    "元学习是一种学习如何学习的算法。\n",
    "\n",
    "**目标**：学习一个对各种task效果最好的初始化参数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_joknw1l"
   },
   "source": [
    "### 模型无关元学习 MAML\n",
    "\n",
    "对于参数初始化的元学习算法有许多，其中模型无关元学习MAML是该类型的元学习算法中的经典。该算法能够让模型快速在多个任务之间迅速收敛，并且达到良好的效果。在介绍算法流程之前，帮助大家理解该算法，我们先从下图开始介绍：\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/t3.png\" width=750 />\n",
    "\n",
    "上图表示的是该算法的训练过程的可视化。图中的$\\theta$表示的是模型的参数的收敛轨迹，其中实线表示的元学习器meta learner的学习轨迹，虚线表示learner在不同任务中学习的轨迹。\n",
    "\n",
    "现在假设我们的元学习器meta learner需要学习三个任务，分别表示1，2，3。learner在这三个任务上分别单独进行学习，会分别收敛到三个不同的位置，分别是$\\theta_1$，$\\theta_2$，$\\theta_3$。而这三个参数所对应的反向传播回来的梯度分别是L1，L2，和L3。而最终对于meta learner的参数$\\theta$的更新则是取自这L1，L2和L3的平均值。\n",
    "\n",
    "为什么这样的训练方式会有效呢，首先meta learner会在三个不同的task单独分别进行训练，也就是对于不同的任务单独进行学习。然后针对在三个任务上的参数，进行求梯度，也就是获取更新的信息。将三者的信息进行平均来更新最初meta learner的参数。这可以形象的理解为，将三种任务上的学习到的知识进行平衡，来更新最初的参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_xhukcib"
   },
   "source": [
    "下图给出了算法的具体流程：\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/t4.png\" width=750 />\n",
    "\n",
    "首先会从所有的任务分布中采样出一个batch的任务，对于这batch中的每个任务，模型都会进行单独的训练，得到一个与任务对应的learner。得到每个任务所对应的learner之后，再从支撑集support set上采样一部分的样本用于进行meta update，将learner在query set上所计算得到的loss来获得梯度。然后将所有learner在各自对应的query set上计算得到的梯度进行平均然后更新meta learner的参数，从而实现整个算法的更新。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_hea1o93"
   },
   "source": [
    "## 联邦学习\n",
    "\n",
    "联邦学习在抛开Non IID的数据环境的前提之下，其训练方式可以看做是一种并行的元学习方式。首先可以将不同节点的数据内容可以看做是不同的任务，那么每个节点就是针对不同的任务进行更新，然后模型的汇聚过程就像是元学习中对于不同任务的梯度进行平均更新元学习器。因此，整体过程就非常像是并行的元学习过程。但是联邦学习和元学习的目标存在区别，联邦学习希望得到的模型的参数是能够在各个节点上表现都不错，对于元学习来说其目标不一定要在各个任务上直接表现得很好，但是他需要针对不同任务能够学习的很快。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_5wlnwvn"
   },
   "source": [
    "## 联邦元学习\n",
    "\n",
    "一种将联邦学习和元学习结合的一种联邦元学习算法。\n",
    "\n",
    "### 算法思想\n",
    "\n",
    "既然联邦学习和元学习如此相似，那么将两种学习模式进行结合会怎么样呢？下图展示了联邦元学习的算法思想：\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/t5.png\" width=750 />\n",
    "\n",
    "联邦元学习主要是将联邦学习中的单机模型训练过程替换成元学习的元学习器的训练过程，也就是将联邦学习的学习模式应用于元学习中，换言之就是用联邦学习的模式来做元学习。图中所展示了联邦元学习的四个步骤分别是：1. 算法分发（元学期分发）2. 模型训练（learner的adaptation）3. 梯度的反向传播 4. 元学习器的更新（梯度汇聚）\n",
    "\n",
    "ux表示的是节点，其中在第一步算法分发过程，节点会先从服务器下载中心节点的元学习器参数。在第二步模型训练中，不同节点就是包含了不同task的节点，每个节点上的learner会在其对应的数据上进行adaptation过程，学习不同任务的信息。在不同任务上收敛之后的learner模型参数为theta，然后在节点上对应的query set上求loss，计算梯度。第三步，将每个节点上的梯度进行汇聚反传给中心节点。第四步，将每个节点上的梯度进行平均后更新中心节点模型参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_5shy9j7"
   },
   "source": [
    "## 实验\n",
    "\n",
    "### 实验设置\n",
    "\n",
    "测试标准：新节点的泛化能力\n",
    "\n",
    "节点设置：80%训练节点，10%验证节点， 10%测试节点\n",
    "\n",
    "样本设置：support set和query set，对support set进行比例p的分割\n",
    "\n",
    "算法设置：FedAVG， FedAVG（Meta），FedMeta（MAML）其中FedAVG（Meta）指的是在FedAVG基础上对测试数据进行finetune少部分轮次\n",
    "\n",
    "数据集：FEMNIST，ShakeSpeare，Sentiment140"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_2sjgksy"
   },
   "source": [
    "### 实验效果\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/t6.png\" width=750 />\n",
    "\n",
    "<img src=\"https://imgbed.momodel.cn/t7.png\" width=750 />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "graffitiCellId": "id_yu2soj1"
   },
   "source": [
    "## 引用\n",
    "\n",
    "[Federated Meta-Learning with Fast Convergence and Efficient Communication](https://arxiv.org/abs/1802.07876)\n",
    "\n",
    "[Federated Meta-Learning with Fast Convergence and Efficient Communication论文笔记](https://ereebay.me/posts/35664/)"
   ]
  }
 ],
 "metadata": {
  "graffiti": {
   "firstAuthorId": "dev",
   "id": "id_d34hdwb",
   "language": "EN"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
